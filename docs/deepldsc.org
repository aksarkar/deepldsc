#+TITLE: deepldsc
#+AUTHOR: Abhishek Sarkar
#+EMAIL: aksarkar@uchicago.edu
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t
#+OPTIONS: broken-links:nil c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+OPTIONS: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
#+OPTIONS: tasks:t tex:t timestamp:t title:t toc:t todo:t |:t
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 25.1.1 (Org mode 9.1.1)
* Setup :noexport:

  #+BEGIN_SRC emacs-lisp
    (setq python-shell-prompt-detect-failure-warning nil)
  #+END_SRC

  #+RESULTS:

  #+BEGIN_SRC shell :var RESOURCES="--mem=36G --partition=gpu2"
    sbatch $RESOURCES --job-name=ipython3 --output=ipython3.out
    #!/bin/bash
    source activate nwas
    rm -f $HOME/.local/share/jupyter/runtime/kernel-aksarkar.json
    ipython3 kernel --ip=$(hostname -i) -f kernel-aksarkar.json
  #+END_SRC

  #+RESULTS:
  : Submitted batch job 37258338

* Get the data

  #+BEGIN_SRC shell :dir $SCRATCH/play
  wget -r -l 1 -A "*.sumstats" "https://data.broadinstitute.org/alkesgroup/sumstats_formatted/"
  curl -sfS "https://data.broadinstitute.org/alkesgroup/LDSCORE/1000G_Phase1_baseline_ldscores.tgz" | tar xz
  curl -sfS "https://data.broadinstitute.org/alkesgroup/LDSCORE/1000G_Phase1_cell_type_ldscores.tgz" | tar xz
  #+END_SRC

  #+BEGIN_SRC ipython :session kernel-aksarkar.json :results raw drawer :async t
    import pandas

    uc = pandas.read_table('/scratch/midway2/aksarkar/play/data.broadinstitute.org/alkesgroup/sumstats_formatted/PASS_Ulcerative_Colitis.sumstats')

    # Hold out chr22
    training_data = pandas.concat(
        uc.merge(chunk, on='SNP') for chrom in range(1, 22)
        for chunk in pandas.read_table('/scratch/midway2/aksarkar/play/baseline/baseline.{}.l2.ldscore.gz'.format(chrom), chunksize=1000)
    )
    test_data = pandas.concat(
        uc.merge(chunk, on='SNP') for chrom in range(22, 23)
        for chunk in pandas.read_table('/scratch/midway2/aksarkar/play/baseline/baseline.{}.l2.ldscore.gz'.format(chrom), chunksize=1000)
    )
    training_data.shape, test_data.shape
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  : ((967394, 63), (13897, 63))
  :END:

  https://www.tensorflow.org/programmers_guide/datasets

* Idea

  ~ldsc~ is a linear model:

  \[ E[\Chi^2] = N \sum_c \tau_c l(j, c) + N a + 1 \]

  \[ y \sim N(N (X w + b), \sigma^2) \]

  Let's try to fit a deep network instead:

  \[ y \sim N(h(X), \sigma^2) \]

  #+BEGIN_SRC ipython :session kernel-aksarkar.json :results none :async t
    import os
    import tensorflow as tf

    feature_columns = training_data.columns[10:]
    training_input = tf.estimator.inputs.pandas_input_fn(
        x=training_data[feature_columns],
        y=training_data['CHISQ'],
        batch_size=1000,
        num_epochs=10,
        shuffle=True,
        target_column='chisq',
    )
    test_input = tf.estimator.inputs.pandas_input_fn(
        x=test_data[feature_columns],
        y=test_data['CHISQ'],
        num_epochs=1,  # This tells evaluate to stop after seeing the full data
        shuffle=False,
        target_column='chisq',
    )
    feature_columns = [tf.feature_column.numeric_column(c) for c in feature_columns]
    deepldsc = tf.contrib.learn.DNNRegressor(
        feature_columns=feature_columns,
        hidden_units=[len(feature_columns) // i for i in (1, 2, 4)],
        optimizer=tf.train.AdamOptimizer(learning_rate=1e-3),
        model_dir=os.path.join(os.getenv('SCRATCH'), 'play', 'model'),
    ).fit(input_fn=training_input).evaluate(input_fn=test_input)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  : 2.7722633
  :END:
