#+TITLE: deepldsc
#+AUTHOR: Abhishek Sarkar
#+EMAIL: aksarkar@uchicago.edu
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t
#+OPTIONS: broken-links:nil c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+OPTIONS: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
#+OPTIONS: tasks:t tex:t timestamp:t title:t toc:t todo:t |:t
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 25.1.1 (Org mode 9.1.1)
* Setup :noexport:

  #+BEGIN_SRC emacs-lisp
    (setq python-shell-prompt-detect-failure-warning nil)
  #+END_SRC

  #+RESULTS:

  #+NAME: ipython3-kernel
  #+BEGIN_SRC shell :dir (concat (file-name-as-directory (getenv "SCRATCH")) "deepldsc") :var RESOURCES="--mem=36G --partition=gpu2 --gres=gpu:1"
    sbatch $RESOURCES --job-name=ipython3 --output=ipython3.out
    #!/bin/bash -l
    source activate deepldsc
    rm -f $HOME/.local/share/jupyter/runtime/kernel-aksarkar.json
    ipython3 kernel --ip=$(hostname -i) -f kernel-aksarkar.json
  #+END_SRC

  #+RESULTS: ipython3-kernel
  : Submitted batch job 38318101

  #+NAME: imports
  #+BEGIN_SRC ipython :session kernel-aksarkar.json :results raw drawer
    import deeplift.conversion.keras_conversion as kc
    import keras
    import os
    import numpy as np
    import pandas as pd
    import tensorflow as tf

    tf.__file__
  #+END_SRC

  #+RESULTS: imports
  :RESULTS:
  : '/home/aksarkar/.conda/envs/deepldsc/lib/python3.6/site-packages/tensorflow/__init__.py'
  :END:

* Get the data

  #+BEGIN_SRC shell :dir $SCRATCH/deepldsc
  wget -r -l 1 -A "*.sumstats" "https://data.broadinstitute.org/alkesgroup/sumstats_formatted/"
  curl -sfS "https://data.broadinstitute.org/alkesgroup/LDSCORE/1000G_Phase1_baseline_ldscores.tgz" | tar xz
  curl -sfS "https://data.broadinstitute.org/alkesgroup/LDSCORE/1000G_Phase1_cell_type_ldscores.tgz" | tar xz
  #+END_SRC

  #+BEGIN_SRC ipython :session kernel-aksarkar.json :results raw drawer :async t
    uc = pd.read_table('/scratch/midway2/aksarkar/deepldsc/data.broadinstitute.org/alkesgroup/sumstats_formatted/PASS_Ulcerative_Colitis.sumstats')

    # Hold out chr22
    training_data = pd.concat(
        uc.merge(chunk, on='SNP') for chrom in range(1, 22)
        for chunk in pd.read_table('/scratch/midway2/aksarkar/deepldsc/baseline/baseline.{}.l2.ldscore.gz'.format(chrom), chunksize=1000)
    )
    test_data = pd.concat(
        uc.merge(chunk, on='SNP') for chrom in range(22, 23)
        for chunk in pd.read_table('/scratch/midway2/aksarkar/deepldsc/baseline/baseline.{}.l2.ldscore.gz'.format(chrom), chunksize=1000)
    )
    training_data.shape, test_data.shape
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  : ((967394, 63), (13897, 63))
  :END:

* Idea

  ~ldsc~ is a linear model:

  \[ E[\Chi^2] = N \sum_c \tau_c l(j, c) + N a + 1 \]

  \[ y \sim N(N (X w + b), \sigma^2) \]

  #+NAME: ldsc
  #+BEGIN_SRC ipython :session kernel-aksarkar.json :results raw drawer :async t
    ldsc = keras.models.Sequential([
      keras.layers.Dense(1, input_dim=53)
    ])
    ldsc.compile(optimizer='rmsprop', loss='mse')
    ldsc.fit(x=training_data.iloc[:,10:].values,
             y=training_data['CHISQ'].values,
             epochs=4,
    )
    ldsc.save(os.path.join(os.getenv('SCRATCH'), 'deepldsc', 'uc-ldsc.hdf5'))
    ldsc.evaluate(x=test_data.iloc[:,10:].values,
                  y=test_data['CHISQ'].values)
  #+END_SRC

  #+RESULTS: ldsc
  :RESULTS:
  : 8.3588527845651832
  :END:

  Let's try to fit a deep network instead:

  \[ y \sim N(h(X), \sigma^2) \]

  #+NAME: deepldsc
  #+BEGIN_SRC ipython :session kernel-aksarkar.json :results raw drawer :async t
    deepldsc = keras.models.Sequential([
      keras.layers.Dense(32, input_dim=53, activation='relu'),
      keras.layers.Dense(16, activation='relu'),
      keras.layers.Dense(1)
    ])
    deepldsc.compile(optimizer=keras.optimizers.RMSprop(lr=1e-4),
                     loss='mse')
    deepldsc.fit(x=training_data.iloc[:,10:].values,
                 y=training_data['CHISQ'].values,
                 epochs=4,
    )
    deepldsc.save(os.path.join(os.getenv('SCRATCH'), 'deepldsc', 'uc-deepldsc.hdf5'))
    deepldsc.evaluate(x=test_data.iloc[:,10:].values,
                      y=test_data['CHISQ'].values)
  #+END_SRC

  #+RESULTS: deepldsc
  :RESULTS:
  : 6.7853382878434942
  :END:

* Interpret the model using deeplift

  #+BEGIN_SRC ipython :session kernel-aksarkar.json :results raw drawer :async t
    deepldsc = keras.models.load_model(os.path.join(os.getenv('SCRATCH'), 'deepldsc', 'uc-deepldsc.hdf5'))
  #+END_SRC

  #+NAME: deeplift
  #+BEGIN_SRC ipython :session kernel-aksarkar.json :results raw drawer :async t
    scores = kc.convert_sequential_model(deepldsc).get_target_contribs_func(find_scores_layer_idx=1, target_layer_idx=-1)(
      task_idx=0,
      input_data_list=[test_data.iloc[:,10:]],
      batch_size=32,
      progress_update=1000,
    )
    scores = pd.DataFrame(scores)
    scores.columns = test_data.columns[10:]
    scores.index = test_data['SNP']
  #+END_SRC

  #+RESULTS: deeplift
  :RESULTS:
  5b6c4135-759e-476c-a651-46a29d5a053f
  :END:

  Unlike ~ldsc~, ~deeplift~ on ~deepldsc~ propagates down to each SNP which
  means we can do things like look for heterogeneity among SNPs.

  #+BEGIN_SRC ipython :ipyfile :session kernel-aksarkar.json :results raw drawer :async t
    import sklearn.manifold

    embedding = sklearn.manifold.TSNE().fit_transform(scores)
    plt.clf()
    plt.plot(embedding[:,0], embedding[:,1])
  #+END_SRC

